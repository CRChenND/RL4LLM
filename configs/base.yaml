model_id: "google/gemma-3-270m-it"
dtype: "float32"
device: "auto"
seed: 42

lora:
  r: 16
  alpha: 16
  dropout: 0.05
  target_modules: ["q_proj","k_proj","v_proj","o_proj"]

max_input_length: 128
max_new_tokens: 10
per_device_train_batch_size: 1
grad_accum: 8
top_p: 0.9

output_dir: "outputs"
log_every: 1
save_every: 50

dataset:
  path: "data/qa_train.jsonl"
  template: "Answer ONLY with the final answer.\n\nQ: {prompt}\nA:"
  max_samples: 8

# semantic reward (Sentence-BERT)
semantic_reward:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  device: "auto"
  cache_path: "outputs/emb_cache.jsonl"
  normalize: true
  rescale01: true
  length_clip: 512

# (optional) judge via OpenRouter â€“ enable only if you want LLM-as-judge
judge:
  provider: "openrouter"
  model: "openai/gpt-4o-mini"
  api_url: "https://openrouter.ai/api/v1/chat/completions"
  api_key_env: "OPENROUTER_API_KEY"
  timeout_s: 30
  max_retries: 3
  cooldown_s: 2
  cache_path: "outputs/judge_cache.jsonl"

secrets:
  ini_path: "secrets.ini"
  env_map:
    OPENROUTER_API_KEY: "OPENROUTER_API_KEY"
