# configs/ppo.yaml
inherit: "configs/base.yaml"

learning_rate: 2e-5
ppo_epochs: 3
target_kl: 0.12
kl_alpha: 0.05
vf_coef: 2.0
ent_coef: 0.005
clip_range: 0.2

# generation
max_input_len: 64
max_new_tokens: 16
grad_accum: 16
reward_scale: 10.0
minibatch_size_tokens: 128

kl_alpha: 0.05
kl_alpha_min: 0.01
kl_alpha_max: 1.0
kl_beta: 0.7
kl_warmup_steps: 5

dev_eval:
  enabled: true
  path: "data/qa_eval.jsonl"
  num_examples: 8
  top_p: 0.0