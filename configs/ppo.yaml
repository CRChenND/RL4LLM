# configs/ppo.yaml
inherit: "configs/base.yaml"

learning_rate: 2e-5
ppo_epochs: 3
target_kl: 0.12
kl_alpha: 0.05
vf_coef: 1.5
ent_coef: 0.005
clip_range: 0.2

# generation
max_input_len: 64
max_new_tokens: 32
grad_accum: 16

minibatch_size_tokens: 128

dev_eval:
  enabled: true
  path: "data/qa_eval.jsonl"
  num_examples: 8
  top_p: 0.0